{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification using\n",
    "#### SVM \n",
    "#### Linear Regression\n",
    "#### Logistic Regression\n",
    "#### PROBIT "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# data from: http://archive.ics.uci.edu/ml/machine-learning-databases/wine/\n",
    "import pandas as pd \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n1) Alcohol\\n2) Malic acid\\n3) Ash\\n4) Alcalinity of ash  \\n5) Magnesium\\n6) Total phenols\\n7) Flavanoids\\n8) Nonflavanoid phenols\\n9) Proanthocyanins\\n10) Color intensity\\n11) Hue\\n12) OD280/OD315 of diluted wines\\n13) Proline\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "1) Alcohol\n",
    "2) Malic acid\n",
    "3) Ash\n",
    "4) Alcalinity of ash  \n",
    "5) Magnesium\n",
    "6) Total phenols\n",
    "7) Flavanoids\n",
    "8) Nonflavanoid phenols\n",
    "9) Proanthocyanins\n",
    "10) Color intensity\n",
    "11) Hue\n",
    "12) OD280/OD315 of diluted wines\n",
    "13) Proline\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleasing and Preparation - Global"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Creating header\n",
    "colnames = ['Alcohol','Malic acid','Ash','Alcalinity of ash','Magnesium','Total phenols','Flavanoid',\\\n",
    "            'Nonflavanoid phenols','Proanthocyanis','Color Intensity', 'Hue','OD280/OD315','Proline']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Reading csv and concatenating the header\n",
    "wineData = pd.read_csv('wine.data.csv', names=colnames, index_col=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Alcohol</th>\n",
       "      <th>Malic acid</th>\n",
       "      <th>Ash</th>\n",
       "      <th>Alcalinity of ash</th>\n",
       "      <th>Magnesium</th>\n",
       "      <th>Total phenols</th>\n",
       "      <th>Flavanoid</th>\n",
       "      <th>Nonflavanoid phenols</th>\n",
       "      <th>Proanthocyanis</th>\n",
       "      <th>Color Intensity</th>\n",
       "      <th>Hue</th>\n",
       "      <th>OD280/OD315</th>\n",
       "      <th>Proline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>14.23</td>\n",
       "      <td>1.71</td>\n",
       "      <td>2.43</td>\n",
       "      <td>15.6</td>\n",
       "      <td>127</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.06</td>\n",
       "      <td>0.28</td>\n",
       "      <td>2.29</td>\n",
       "      <td>5.64</td>\n",
       "      <td>1.04</td>\n",
       "      <td>3.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>13.20</td>\n",
       "      <td>1.78</td>\n",
       "      <td>2.14</td>\n",
       "      <td>11.2</td>\n",
       "      <td>100</td>\n",
       "      <td>2.65</td>\n",
       "      <td>2.76</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1.28</td>\n",
       "      <td>4.38</td>\n",
       "      <td>1.05</td>\n",
       "      <td>3.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>13.16</td>\n",
       "      <td>2.36</td>\n",
       "      <td>2.67</td>\n",
       "      <td>18.6</td>\n",
       "      <td>101</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.24</td>\n",
       "      <td>0.30</td>\n",
       "      <td>2.81</td>\n",
       "      <td>5.68</td>\n",
       "      <td>1.03</td>\n",
       "      <td>3.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>14.37</td>\n",
       "      <td>1.95</td>\n",
       "      <td>2.50</td>\n",
       "      <td>16.8</td>\n",
       "      <td>113</td>\n",
       "      <td>3.85</td>\n",
       "      <td>3.49</td>\n",
       "      <td>0.24</td>\n",
       "      <td>2.18</td>\n",
       "      <td>7.80</td>\n",
       "      <td>0.86</td>\n",
       "      <td>3.45</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Alcohol  Malic acid   Ash  Alcalinity of ash  Magnesium  Total phenols  \\\n",
       "0        1       14.23  1.71               2.43       15.6            127   \n",
       "1        1       13.20  1.78               2.14       11.2            100   \n",
       "2        1       13.16  2.36               2.67       18.6            101   \n",
       "3        1       14.37  1.95               2.50       16.8            113   \n",
       "\n",
       "   Flavanoid  Nonflavanoid phenols  Proanthocyanis  Color Intensity   Hue  \\\n",
       "0       2.80                  3.06            0.28             2.29  5.64   \n",
       "1       2.65                  2.76            0.26             1.28  4.38   \n",
       "2       2.80                  3.24            0.30             2.81  5.68   \n",
       "3       3.85                  3.49            0.24             2.18  7.80   \n",
       "\n",
       "   OD280/OD315  Proline  \n",
       "0         1.04     3.92  \n",
       "1         1.05     3.40  \n",
       "2         1.03     3.17  \n",
       "3         0.86     3.45  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Glimpse on the data\n",
    "wineData.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Alcohol</th>\n",
       "      <th>Malic acid</th>\n",
       "      <th>Ash</th>\n",
       "      <th>Alcalinity of ash</th>\n",
       "      <th>Magnesium</th>\n",
       "      <th>Total phenols</th>\n",
       "      <th>Flavanoid</th>\n",
       "      <th>Nonflavanoid phenols</th>\n",
       "      <th>Proanthocyanis</th>\n",
       "      <th>Color Intensity</th>\n",
       "      <th>Hue</th>\n",
       "      <th>OD280/OD315</th>\n",
       "      <th>Proline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>178.000000</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>178.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.938202</td>\n",
       "      <td>13.000618</td>\n",
       "      <td>2.336348</td>\n",
       "      <td>2.366517</td>\n",
       "      <td>19.494944</td>\n",
       "      <td>99.741573</td>\n",
       "      <td>2.295112</td>\n",
       "      <td>2.029270</td>\n",
       "      <td>0.361854</td>\n",
       "      <td>1.590899</td>\n",
       "      <td>5.058090</td>\n",
       "      <td>0.957449</td>\n",
       "      <td>2.611685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.775035</td>\n",
       "      <td>0.811827</td>\n",
       "      <td>1.117146</td>\n",
       "      <td>0.274344</td>\n",
       "      <td>3.339564</td>\n",
       "      <td>14.282484</td>\n",
       "      <td>0.625851</td>\n",
       "      <td>0.998859</td>\n",
       "      <td>0.124453</td>\n",
       "      <td>0.572359</td>\n",
       "      <td>2.318286</td>\n",
       "      <td>0.228572</td>\n",
       "      <td>0.709990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>11.030000</td>\n",
       "      <td>0.740000</td>\n",
       "      <td>1.360000</td>\n",
       "      <td>10.600000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>0.980000</td>\n",
       "      <td>0.340000</td>\n",
       "      <td>0.130000</td>\n",
       "      <td>0.410000</td>\n",
       "      <td>1.280000</td>\n",
       "      <td>0.480000</td>\n",
       "      <td>1.270000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>12.362500</td>\n",
       "      <td>1.602500</td>\n",
       "      <td>2.210000</td>\n",
       "      <td>17.200000</td>\n",
       "      <td>88.000000</td>\n",
       "      <td>1.742500</td>\n",
       "      <td>1.205000</td>\n",
       "      <td>0.270000</td>\n",
       "      <td>1.250000</td>\n",
       "      <td>3.220000</td>\n",
       "      <td>0.782500</td>\n",
       "      <td>1.937500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>13.050000</td>\n",
       "      <td>1.865000</td>\n",
       "      <td>2.360000</td>\n",
       "      <td>19.500000</td>\n",
       "      <td>98.000000</td>\n",
       "      <td>2.355000</td>\n",
       "      <td>2.135000</td>\n",
       "      <td>0.340000</td>\n",
       "      <td>1.555000</td>\n",
       "      <td>4.690000</td>\n",
       "      <td>0.965000</td>\n",
       "      <td>2.780000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>13.677500</td>\n",
       "      <td>3.082500</td>\n",
       "      <td>2.557500</td>\n",
       "      <td>21.500000</td>\n",
       "      <td>107.000000</td>\n",
       "      <td>2.800000</td>\n",
       "      <td>2.875000</td>\n",
       "      <td>0.437500</td>\n",
       "      <td>1.950000</td>\n",
       "      <td>6.200000</td>\n",
       "      <td>1.120000</td>\n",
       "      <td>3.170000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>14.830000</td>\n",
       "      <td>5.800000</td>\n",
       "      <td>3.230000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>162.000000</td>\n",
       "      <td>3.880000</td>\n",
       "      <td>5.080000</td>\n",
       "      <td>0.660000</td>\n",
       "      <td>3.580000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>1.710000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Alcohol  Malic acid         Ash  Alcalinity of ash   Magnesium  \\\n",
       "count  178.000000  178.000000  178.000000         178.000000  178.000000   \n",
       "mean     1.938202   13.000618    2.336348           2.366517   19.494944   \n",
       "std      0.775035    0.811827    1.117146           0.274344    3.339564   \n",
       "min      1.000000   11.030000    0.740000           1.360000   10.600000   \n",
       "25%      1.000000   12.362500    1.602500           2.210000   17.200000   \n",
       "50%      2.000000   13.050000    1.865000           2.360000   19.500000   \n",
       "75%      3.000000   13.677500    3.082500           2.557500   21.500000   \n",
       "max      3.000000   14.830000    5.800000           3.230000   30.000000   \n",
       "\n",
       "       Total phenols   Flavanoid  Nonflavanoid phenols  Proanthocyanis  \\\n",
       "count     178.000000  178.000000            178.000000      178.000000   \n",
       "mean       99.741573    2.295112              2.029270        0.361854   \n",
       "std        14.282484    0.625851              0.998859        0.124453   \n",
       "min        70.000000    0.980000              0.340000        0.130000   \n",
       "25%        88.000000    1.742500              1.205000        0.270000   \n",
       "50%        98.000000    2.355000              2.135000        0.340000   \n",
       "75%       107.000000    2.800000              2.875000        0.437500   \n",
       "max       162.000000    3.880000              5.080000        0.660000   \n",
       "\n",
       "       Color Intensity         Hue  OD280/OD315     Proline  \n",
       "count       178.000000  178.000000   178.000000  178.000000  \n",
       "mean          1.590899    5.058090     0.957449    2.611685  \n",
       "std           0.572359    2.318286     0.228572    0.709990  \n",
       "min           0.410000    1.280000     0.480000    1.270000  \n",
       "25%           1.250000    3.220000     0.782500    1.937500  \n",
       "50%           1.555000    4.690000     0.965000    2.780000  \n",
       "75%           1.950000    6.200000     1.120000    3.170000  \n",
       "max           3.580000   13.000000     1.710000    4.000000  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Summary of the dataset\n",
    "wineData.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM - Linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Importing library\n",
    "from sklearn import svm, linear_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Preparation - Local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading csv file into a readable format for sklearn\n",
    "data =  np.loadtxt(fname = 'wine.data.csv', delimiter = ',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  1.00000000e+00,   1.42300000e+01,   1.71000000e+00,\n",
       "         2.43000000e+00,   1.56000000e+01,   1.27000000e+02,\n",
       "         2.80000000e+00,   3.06000000e+00,   2.80000000e-01,\n",
       "         2.29000000e+00,   5.64000000e+00,   1.04000000e+00,\n",
       "         3.92000000e+00,   1.06500000e+03])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Getting the DV and IV\n",
    "y = data[:, 0]\n",
    "\n",
    "x = data[:, 4:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'svm' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-a39221be33bc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Linear\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msvm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSVC\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'linear'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'svm' is not defined"
     ]
    }
   ],
   "source": [
    "# Instantiating the classification object \n",
    "\n",
    "# Linear\n",
    "clf = svm.SVC(kernel='linear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape=None, degree=3, gamma='auto', kernel='linear',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2.])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lets predict to \n",
    "clf.predict([[20]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Plotting \n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x10bc89358>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAD8CAYAAABw1c+bAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nC35jjHEZC35jjHEZC35jjHGZ/x8OOA56ZP/ImgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10bbbbb70>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(x, y, c=y, cmap=plt.cm.coolwarm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification with Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pylab as pl\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Preparation - Local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Alcohol', 'Malic acid', 'Ash', 'Alcalinity of ash', 'Magnesium',\n",
       "       'Total phenols', 'Flavanoid', 'Nonflavanoid phenols',\n",
       "       'Proanthocyanis', 'Color Intensity', 'Hue', 'OD280/OD315', 'Proline'], dtype=object)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wineData.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Magnesium  10.6  11.2  11.4  12.0  12.4  13.2  14.0  14.6  14.8  15.0  ...   \\\n",
      "Alcohol                                                                ...    \n",
      "1             0     1     1     1     1     1     2     1     0     1  ...    \n",
      "2             1     0     0     0     0     0     0     0     1     1  ...    \n",
      "3             0     0     0     0     0     0     0     0     0     0  ...    \n",
      "\n",
      "Magnesium  23.6  24.0  24.5  25.0  25.5  26.0  26.5  27.0  28.5  30.0  \n",
      "Alcohol                                                                \n",
      "1             0     0     0     1     0     0     0     0     0     0  \n",
      "2             1     2     1     1     0     1     1     0     2     1  \n",
      "3             0     3     2     3     1     0     0     1     0     0  \n",
      "\n",
      "[3 rows x 63 columns]\n"
     ]
    }
   ],
   "source": [
    "# TODO EXPLAIN CROSS TAB ANALYSIS\n",
    "print(pd.crosstab(wineData['Alcohol'], wineData['Magnesium']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get_dummies creates a new DataFrame with binary indicator \n",
    "# variables for each category/option in the column specified.\n",
    "# Very useful when your categorical variables are nomimal (no ordered)\n",
    "dummy_ranks = pd.get_dummies(wineData['Alcohol'], prefix='Alcohol')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Alcohol_1</th>\n",
       "      <th>Alcohol_2</th>\n",
       "      <th>Alcohol_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Alcohol_1  Alcohol_2  Alcohol_3\n",
       "173          0          0          1\n",
       "174          0          0          1\n",
       "175          0          0          1\n",
       "176          0          0          1\n",
       "177          0          0          1"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy_ranks.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Coping the dataset to mantain the base dataset\n",
    "data = wineData.iloc[:,0:7].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Merging the datasets\n",
    "data = data.join(dummy_ranks.loc[:, 'Alcohol_2':])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO EXPLAIN INTERCEPT AND THE IMPORTANCE OF IT\n",
    "data['Intercept'] = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Alcohol</th>\n",
       "      <th>Malic acid</th>\n",
       "      <th>Ash</th>\n",
       "      <th>Alcalinity of ash</th>\n",
       "      <th>Magnesium</th>\n",
       "      <th>Total phenols</th>\n",
       "      <th>Flavanoid</th>\n",
       "      <th>Alcohol_2</th>\n",
       "      <th>Alcohol_3</th>\n",
       "      <th>Intercept</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>14.23</td>\n",
       "      <td>1.71</td>\n",
       "      <td>2.43</td>\n",
       "      <td>15.6</td>\n",
       "      <td>127</td>\n",
       "      <td>2.80</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>13.20</td>\n",
       "      <td>1.78</td>\n",
       "      <td>2.14</td>\n",
       "      <td>11.2</td>\n",
       "      <td>100</td>\n",
       "      <td>2.65</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Alcohol  Malic acid   Ash  Alcalinity of ash  Magnesium  Total phenols  \\\n",
       "0        1       14.23  1.71               2.43       15.6            127   \n",
       "1        1       13.20  1.78               2.14       11.2            100   \n",
       "\n",
       "   Flavanoid  Alcohol_2  Alcohol_3  Intercept  \n",
       "0       2.80          0          0        1.0  \n",
       "1       2.65          0          0        1.0  "
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def ClassificationLR(dataset):\n",
    "\n",
    "    # Spliting the data into train and test\n",
    "    # 80% -> Training \n",
    "    # 20% -> Testing\n",
    "    \n",
    "    #trainData = dataset.iloc[:int(len(dataset)*.8),:]\n",
    "    #testData = dataset.iloc[int(len(dataset)*.8+1):]\n",
    "    trainData, testData = train_test_split(dataset, test_size = 0.3)\n",
    "    \n",
    "    # Linear regression\n",
    "    # On the train data the dependet variable and the intercept are removed\n",
    "    lr = sm.OLS(trainData['Alcohol'], trainData.iloc[:,1:-1])\n",
    "\n",
    "    # Fitting\n",
    "    res = lr.fit()\n",
    "\n",
    "    print(res.summary())\n",
    " \n",
    "    # Generating the odds ratio, based on the exponential of each coefficient \n",
    "    print(\"\\n-----\\nOdds Ratio\\n\")\n",
    "    print(np.exp(res.params))\n",
    "    \n",
    "    # Adding the predicted values on another colunm\n",
    "    dataset['Admit Pred'] = res.predict((testData.iloc[:,2:]))\n",
    "    \n",
    "    #print(res.predict(testData.iloc[:,2:]))\n",
    "    return res, dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                Alcohol   R-squared:                       1.000\n",
      "Model:                            OLS   Adj. R-squared:                  1.000\n",
      "Method:                 Least Squares   F-statistic:                 5.830e+04\n",
      "Date:                Thu, 01 Jun 2017   Prob (F-statistic):          3.18e-205\n",
      "Time:                        10:54:08   Log-Likelihood:                 248.79\n",
      "No. Observations:                 124   AIC:                            -481.6\n",
      "Df Residuals:                     116   BIC:                            -459.0\n",
      "Df Model:                           8                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "=====================================================================================\n",
      "                        coef    std err          t      P>|t|      [0.025      0.975]\n",
      "-------------------------------------------------------------------------------------\n",
      "Malic acid            0.0605      0.003     23.510      0.000       0.055       0.066\n",
      "Ash                  -0.0025      0.003     -0.752      0.454      -0.009       0.004\n",
      "Alcalinity of ash     0.0355      0.016      2.194      0.030       0.003       0.068\n",
      "Magnesium             0.0010      0.002      0.665      0.507      -0.002       0.004\n",
      "Total phenols         0.0004      0.000      1.702      0.091   -7.07e-05       0.001\n",
      "Flavanoid             0.0080      0.007      1.085      0.280      -0.007       0.023\n",
      "Alcohol_2             1.1080      0.009    118.289      0.000       1.089       1.127\n",
      "Alcohol_3             2.0502      0.013    159.050      0.000       2.025       2.076\n",
      "==============================================================================\n",
      "Omnibus:                        1.573   Durbin-Watson:                   2.142\n",
      "Prob(Omnibus):                  0.455   Jarque-Bera (JB):                1.299\n",
      "Skew:                           0.049   Prob(JB):                        0.522\n",
      "Kurtosis:                       2.508   Cond. No.                         601.\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "\n",
      "-----\n",
      "Odds Ratio\n",
      "\n",
      "Malic acid           1.062412\n",
      "Ash                  0.997470\n",
      "Alcalinity of ash    1.036188\n",
      "Magnesium            1.001008\n",
      "Total phenols        1.000432\n",
      "Flavanoid            1.008018\n",
      "Alcohol_2            3.028409\n",
      "Alcohol_3            7.769232\n",
      "dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<statsmodels.regression.linear_model.RegressionResultsWrapper at 0x10bb7f588>,\n",
       "      Alcohol  Malic acid   Ash  Alcalinity of ash  Magnesium  Total phenols  \\\n",
       " 0          1       14.23  1.71               2.43       15.6            127   \n",
       " 1          1       13.20  1.78               2.14       11.2            100   \n",
       " 2          1       13.16  2.36               2.67       18.6            101   \n",
       " 3          1       14.37  1.95               2.50       16.8            113   \n",
       " 4          1       13.24  2.59               2.87       21.0            118   \n",
       " 5          1       14.20  1.76               2.45       15.2            112   \n",
       " 6          1       14.39  1.87               2.45       14.6             96   \n",
       " 7          1       14.06  2.15               2.61       17.6            121   \n",
       " 8          1       14.83  1.64               2.17       14.0             97   \n",
       " 9          1       13.86  1.35               2.27       16.0             98   \n",
       " 10         1       14.10  2.16               2.30       18.0            105   \n",
       " 11         1       14.12  1.48               2.32       16.8             95   \n",
       " 12         1       13.75  1.73               2.41       16.0             89   \n",
       " 13         1       14.75  1.73               2.39       11.4             91   \n",
       " 14         1       14.38  1.87               2.38       12.0            102   \n",
       " 15         1       13.63  1.81               2.70       17.2            112   \n",
       " 16         1       14.30  1.92               2.72       20.0            120   \n",
       " 17         1       13.83  1.57               2.62       20.0            115   \n",
       " 18         1       14.19  1.59               2.48       16.5            108   \n",
       " 19         1       13.64  3.10               2.56       15.2            116   \n",
       " 20         1       14.06  1.63               2.28       16.0            126   \n",
       " 21         1       12.93  3.80               2.65       18.6            102   \n",
       " 22         1       13.71  1.86               2.36       16.6            101   \n",
       " 23         1       12.85  1.60               2.52       17.8             95   \n",
       " 24         1       13.50  1.81               2.61       20.0             96   \n",
       " 25         1       13.05  2.05               3.22       25.0            124   \n",
       " 26         1       13.39  1.77               2.62       16.1             93   \n",
       " 27         1       13.30  1.72               2.14       17.0             94   \n",
       " 28         1       13.87  1.90               2.80       19.4            107   \n",
       " 29         1       14.02  1.68               2.21       16.0             96   \n",
       " ..       ...         ...   ...                ...        ...            ...   \n",
       " 148        3       13.32  3.24               2.38       21.5             92   \n",
       " 149        3       13.08  3.90               2.36       21.5            113   \n",
       " 150        3       13.50  3.12               2.62       24.0            123   \n",
       " 151        3       12.79  2.67               2.48       22.0            112   \n",
       " 152        3       13.11  1.90               2.75       25.5            116   \n",
       " 153        3       13.23  3.30               2.28       18.5             98   \n",
       " 154        3       12.58  1.29               2.10       20.0            103   \n",
       " 155        3       13.17  5.19               2.32       22.0             93   \n",
       " 156        3       13.84  4.12               2.38       19.5             89   \n",
       " 157        3       12.45  3.03               2.64       27.0             97   \n",
       " 158        3       14.34  1.68               2.70       25.0             98   \n",
       " 159        3       13.48  1.67               2.64       22.5             89   \n",
       " 160        3       12.36  3.83               2.38       21.0             88   \n",
       " 161        3       13.69  3.26               2.54       20.0            107   \n",
       " 162        3       12.85  3.27               2.58       22.0            106   \n",
       " 163        3       12.96  3.45               2.35       18.5            106   \n",
       " 164        3       13.78  2.76               2.30       22.0             90   \n",
       " 165        3       13.73  4.36               2.26       22.5             88   \n",
       " 166        3       13.45  3.70               2.60       23.0            111   \n",
       " 167        3       12.82  3.37               2.30       19.5             88   \n",
       " 168        3       13.58  2.58               2.69       24.5            105   \n",
       " 169        3       13.40  4.60               2.86       25.0            112   \n",
       " 170        3       12.20  3.03               2.32       19.0             96   \n",
       " 171        3       12.77  2.39               2.28       19.5             86   \n",
       " 172        3       14.16  2.51               2.48       20.0             91   \n",
       " 173        3       13.71  5.65               2.45       20.5             95   \n",
       " 174        3       13.40  3.91               2.48       23.0            102   \n",
       " 175        3       13.27  4.28               2.26       20.0            120   \n",
       " 176        3       13.17  2.59               2.37       20.0            120   \n",
       " 177        3       14.13  4.10               2.74       24.5             96   \n",
       " \n",
       "      Flavanoid  Alcohol_2  Alcohol_3  Intercept  Admit Pred  \n",
       " 0         2.80          0          0        1.0    2.831296  \n",
       " 1         2.65          0          0        1.0         NaN  \n",
       " 2         2.80          0          0        1.0         NaN  \n",
       " 3         3.85          0          0        1.0         NaN  \n",
       " 4         2.80          0          0        1.0         NaN  \n",
       " 5         3.27          0          0        1.0         NaN  \n",
       " 6         2.50          0          0        1.0         NaN  \n",
       " 7         2.60          0          0        1.0         NaN  \n",
       " 8         2.80          0          0        1.0    2.740607  \n",
       " 9         2.98          0          0        1.0         NaN  \n",
       " 10        2.95          0          0        1.0         NaN  \n",
       " 11        2.20          0          0        1.0         NaN  \n",
       " 12        2.60          0          0        1.0         NaN  \n",
       " 13        3.10          0          0        1.0         NaN  \n",
       " 14        3.30          0          0        1.0         NaN  \n",
       " 15        2.85          0          0        1.0         NaN  \n",
       " 16        2.80          0          0        1.0         NaN  \n",
       " 17        2.95          0          0        1.0         NaN  \n",
       " 18        3.30          0          0        1.0         NaN  \n",
       " 19        2.70          0          0        1.0         NaN  \n",
       " 20        3.00          0          0        1.0         NaN  \n",
       " 21        2.41          0          0        1.0         NaN  \n",
       " 22        2.61          0          0        1.0         NaN  \n",
       " 23        2.48          0          0        1.0         NaN  \n",
       " 24        2.53          0          0        1.0    2.961953  \n",
       " 25        2.63          0          0        1.0    3.180942  \n",
       " 26        2.85          0          0        1.0         NaN  \n",
       " 27        2.40          0          0        1.0         NaN  \n",
       " 28        2.95          0          0        1.0         NaN  \n",
       " 29        2.65          0          0        1.0    2.812952  \n",
       " ..         ...        ...        ...        ...         ...  \n",
       " 148       1.93          0          1        1.0         NaN  \n",
       " 149       1.41          0          1        1.0         NaN  \n",
       " 150       1.40          0          1        1.0         NaN  \n",
       " 151       1.48          0          1        1.0         NaN  \n",
       " 152       2.20          0          1        1.0         NaN  \n",
       " 153       1.80          0          1        1.0         NaN  \n",
       " 154       1.48          0          1        1.0         NaN  \n",
       " 155       1.74          0          1        1.0         NaN  \n",
       " 156       1.80          0          1        1.0         NaN  \n",
       " 157       1.90          0          1        1.0    4.393354  \n",
       " 158       2.80          0          1        1.0    4.241769  \n",
       " 159       2.60          0          1        1.0    4.143287  \n",
       " 160       2.30          0          1        1.0         NaN  \n",
       " 161       1.83          0          1        1.0         NaN  \n",
       " 162       1.65          0          1        1.0    4.239253  \n",
       " 163       1.39          0          1        1.0    4.126199  \n",
       " 164       1.35          0          1        1.0         NaN  \n",
       " 165       1.28          0          1        1.0    4.305529  \n",
       " 166       1.70          0          1        1.0         NaN  \n",
       " 167       1.48          0          1        1.0         NaN  \n",
       " 168       1.55          0          1        1.0         NaN  \n",
       " 169       1.98          0          1        1.0         NaN  \n",
       " 170       1.25          0          1        1.0         NaN  \n",
       " 171       1.39          0          1        1.0         NaN  \n",
       " 172       1.68          0          1        1.0    4.107294  \n",
       " 173       1.68          0          1        1.0    4.319276  \n",
       " 174       1.80          0          1        1.0         NaN  \n",
       " 175       1.59          0          1        1.0         NaN  \n",
       " 176       1.65          0          1        1.0    4.141627  \n",
       " 177       2.05          0          1        1.0         NaN  \n",
       " \n",
       " [178 rows x 11 columns])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ClassificationLR(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Alcohol</th>\n",
       "      <th>Malic acid</th>\n",
       "      <th>Ash</th>\n",
       "      <th>Alcalinity of ash</th>\n",
       "      <th>Magnesium</th>\n",
       "      <th>Total phenols</th>\n",
       "      <th>Flavanoid</th>\n",
       "      <th>Alcohol_2</th>\n",
       "      <th>Alcohol_3</th>\n",
       "      <th>Intercept</th>\n",
       "      <th>Admit Pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>14.23</td>\n",
       "      <td>1.71</td>\n",
       "      <td>2.43</td>\n",
       "      <td>15.6</td>\n",
       "      <td>127</td>\n",
       "      <td>2.80</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.831296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>14.83</td>\n",
       "      <td>1.64</td>\n",
       "      <td>2.17</td>\n",
       "      <td>14.0</td>\n",
       "      <td>97</td>\n",
       "      <td>2.80</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.740607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1</td>\n",
       "      <td>13.50</td>\n",
       "      <td>1.81</td>\n",
       "      <td>2.61</td>\n",
       "      <td>20.0</td>\n",
       "      <td>96</td>\n",
       "      <td>2.53</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.961953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1</td>\n",
       "      <td>13.05</td>\n",
       "      <td>2.05</td>\n",
       "      <td>3.22</td>\n",
       "      <td>25.0</td>\n",
       "      <td>124</td>\n",
       "      <td>2.63</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.180942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1</td>\n",
       "      <td>14.02</td>\n",
       "      <td>1.68</td>\n",
       "      <td>2.21</td>\n",
       "      <td>16.0</td>\n",
       "      <td>96</td>\n",
       "      <td>2.65</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.812952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>1</td>\n",
       "      <td>13.51</td>\n",
       "      <td>1.80</td>\n",
       "      <td>2.65</td>\n",
       "      <td>19.0</td>\n",
       "      <td>110</td>\n",
       "      <td>2.35</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.939728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>1</td>\n",
       "      <td>13.28</td>\n",
       "      <td>1.64</td>\n",
       "      <td>2.84</td>\n",
       "      <td>15.5</td>\n",
       "      <td>110</td>\n",
       "      <td>2.60</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.805247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>1</td>\n",
       "      <td>13.88</td>\n",
       "      <td>1.89</td>\n",
       "      <td>2.59</td>\n",
       "      <td>15.0</td>\n",
       "      <td>101</td>\n",
       "      <td>3.25</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.794452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>1</td>\n",
       "      <td>14.21</td>\n",
       "      <td>4.04</td>\n",
       "      <td>2.44</td>\n",
       "      <td>18.9</td>\n",
       "      <td>111</td>\n",
       "      <td>2.85</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.073542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>1</td>\n",
       "      <td>13.90</td>\n",
       "      <td>1.68</td>\n",
       "      <td>2.12</td>\n",
       "      <td>16.0</td>\n",
       "      <td>101</td>\n",
       "      <td>3.10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.818413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>1</td>\n",
       "      <td>13.83</td>\n",
       "      <td>1.65</td>\n",
       "      <td>2.60</td>\n",
       "      <td>17.2</td>\n",
       "      <td>94</td>\n",
       "      <td>2.45</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.850705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>1</td>\n",
       "      <td>13.77</td>\n",
       "      <td>1.90</td>\n",
       "      <td>2.68</td>\n",
       "      <td>17.1</td>\n",
       "      <td>115</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.883483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>1</td>\n",
       "      <td>14.22</td>\n",
       "      <td>1.70</td>\n",
       "      <td>2.30</td>\n",
       "      <td>16.3</td>\n",
       "      <td>118</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.847007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>2</td>\n",
       "      <td>12.17</td>\n",
       "      <td>1.45</td>\n",
       "      <td>2.53</td>\n",
       "      <td>19.0</td>\n",
       "      <td>104</td>\n",
       "      <td>1.89</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.920584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>2</td>\n",
       "      <td>13.34</td>\n",
       "      <td>0.94</td>\n",
       "      <td>2.36</td>\n",
       "      <td>17.0</td>\n",
       "      <td>110</td>\n",
       "      <td>2.53</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.825363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>2</td>\n",
       "      <td>12.21</td>\n",
       "      <td>1.19</td>\n",
       "      <td>1.75</td>\n",
       "      <td>16.8</td>\n",
       "      <td>151</td>\n",
       "      <td>1.85</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.875957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>2</td>\n",
       "      <td>12.29</td>\n",
       "      <td>1.61</td>\n",
       "      <td>2.21</td>\n",
       "      <td>20.4</td>\n",
       "      <td>103</td>\n",
       "      <td>1.10</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.979501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>2</td>\n",
       "      <td>13.86</td>\n",
       "      <td>1.51</td>\n",
       "      <td>2.67</td>\n",
       "      <td>25.0</td>\n",
       "      <td>86</td>\n",
       "      <td>2.95</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.119474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>2</td>\n",
       "      <td>12.99</td>\n",
       "      <td>1.67</td>\n",
       "      <td>2.60</td>\n",
       "      <td>30.0</td>\n",
       "      <td>139</td>\n",
       "      <td>3.30</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.360643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>2</td>\n",
       "      <td>13.03</td>\n",
       "      <td>0.90</td>\n",
       "      <td>1.71</td>\n",
       "      <td>16.0</td>\n",
       "      <td>86</td>\n",
       "      <td>1.95</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.764603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>2</td>\n",
       "      <td>12.70</td>\n",
       "      <td>3.87</td>\n",
       "      <td>2.40</td>\n",
       "      <td>23.0</td>\n",
       "      <td>101</td>\n",
       "      <td>2.83</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.207002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>2</td>\n",
       "      <td>12.08</td>\n",
       "      <td>1.13</td>\n",
       "      <td>2.51</td>\n",
       "      <td>24.0</td>\n",
       "      <td>78</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.052852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>2</td>\n",
       "      <td>12.67</td>\n",
       "      <td>0.98</td>\n",
       "      <td>2.24</td>\n",
       "      <td>18.0</td>\n",
       "      <td>99</td>\n",
       "      <td>2.20</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.852410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>2</td>\n",
       "      <td>12.16</td>\n",
       "      <td>1.61</td>\n",
       "      <td>2.31</td>\n",
       "      <td>22.8</td>\n",
       "      <td>90</td>\n",
       "      <td>1.78</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.051758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>2</td>\n",
       "      <td>12.08</td>\n",
       "      <td>1.33</td>\n",
       "      <td>2.30</td>\n",
       "      <td>23.6</td>\n",
       "      <td>70</td>\n",
       "      <td>2.20</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.043297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>2</td>\n",
       "      <td>12.08</td>\n",
       "      <td>1.83</td>\n",
       "      <td>2.32</td>\n",
       "      <td>18.5</td>\n",
       "      <td>81</td>\n",
       "      <td>1.60</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.903044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>2</td>\n",
       "      <td>12.69</td>\n",
       "      <td>1.53</td>\n",
       "      <td>2.26</td>\n",
       "      <td>20.7</td>\n",
       "      <td>80</td>\n",
       "      <td>1.38</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.962139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>2</td>\n",
       "      <td>11.81</td>\n",
       "      <td>2.12</td>\n",
       "      <td>2.74</td>\n",
       "      <td>21.5</td>\n",
       "      <td>134</td>\n",
       "      <td>1.60</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.079594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>2</td>\n",
       "      <td>12.34</td>\n",
       "      <td>2.45</td>\n",
       "      <td>2.46</td>\n",
       "      <td>21.0</td>\n",
       "      <td>98</td>\n",
       "      <td>2.56</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.046644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>2</td>\n",
       "      <td>12.51</td>\n",
       "      <td>1.73</td>\n",
       "      <td>1.98</td>\n",
       "      <td>20.5</td>\n",
       "      <td>85</td>\n",
       "      <td>2.20</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.973239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>2</td>\n",
       "      <td>12.72</td>\n",
       "      <td>1.75</td>\n",
       "      <td>2.28</td>\n",
       "      <td>22.5</td>\n",
       "      <td>84</td>\n",
       "      <td>1.38</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.043426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>2</td>\n",
       "      <td>12.22</td>\n",
       "      <td>1.29</td>\n",
       "      <td>1.94</td>\n",
       "      <td>19.0</td>\n",
       "      <td>92</td>\n",
       "      <td>2.36</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.900502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>2</td>\n",
       "      <td>12.08</td>\n",
       "      <td>1.39</td>\n",
       "      <td>2.50</td>\n",
       "      <td>22.5</td>\n",
       "      <td>84</td>\n",
       "      <td>2.56</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.021583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>2</td>\n",
       "      <td>11.82</td>\n",
       "      <td>1.47</td>\n",
       "      <td>1.99</td>\n",
       "      <td>20.8</td>\n",
       "      <td>86</td>\n",
       "      <td>1.98</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.969050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>2</td>\n",
       "      <td>12.42</td>\n",
       "      <td>1.61</td>\n",
       "      <td>2.19</td>\n",
       "      <td>22.5</td>\n",
       "      <td>108</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.059631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>2</td>\n",
       "      <td>12.77</td>\n",
       "      <td>3.43</td>\n",
       "      <td>1.98</td>\n",
       "      <td>16.0</td>\n",
       "      <td>80</td>\n",
       "      <td>1.63</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.910905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>2</td>\n",
       "      <td>11.45</td>\n",
       "      <td>2.40</td>\n",
       "      <td>2.42</td>\n",
       "      <td>20.0</td>\n",
       "      <td>96</td>\n",
       "      <td>2.90</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.006300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>2</td>\n",
       "      <td>11.87</td>\n",
       "      <td>4.31</td>\n",
       "      <td>2.39</td>\n",
       "      <td>21.0</td>\n",
       "      <td>82</td>\n",
       "      <td>2.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.143434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>2</td>\n",
       "      <td>12.37</td>\n",
       "      <td>1.63</td>\n",
       "      <td>2.30</td>\n",
       "      <td>24.5</td>\n",
       "      <td>88</td>\n",
       "      <td>2.22</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.111602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>2</td>\n",
       "      <td>12.04</td>\n",
       "      <td>4.30</td>\n",
       "      <td>2.38</td>\n",
       "      <td>22.0</td>\n",
       "      <td>80</td>\n",
       "      <td>2.10</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.176060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>3</td>\n",
       "      <td>12.86</td>\n",
       "      <td>1.35</td>\n",
       "      <td>2.32</td>\n",
       "      <td>18.0</td>\n",
       "      <td>122</td>\n",
       "      <td>1.51</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.997539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>3</td>\n",
       "      <td>12.88</td>\n",
       "      <td>2.99</td>\n",
       "      <td>2.40</td>\n",
       "      <td>20.0</td>\n",
       "      <td>104</td>\n",
       "      <td>1.30</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.149493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>3</td>\n",
       "      <td>12.25</td>\n",
       "      <td>4.72</td>\n",
       "      <td>2.54</td>\n",
       "      <td>21.0</td>\n",
       "      <td>89</td>\n",
       "      <td>1.38</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.274343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>3</td>\n",
       "      <td>13.36</td>\n",
       "      <td>2.56</td>\n",
       "      <td>2.35</td>\n",
       "      <td>20.0</td>\n",
       "      <td>89</td>\n",
       "      <td>1.40</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.108514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>3</td>\n",
       "      <td>13.16</td>\n",
       "      <td>3.57</td>\n",
       "      <td>2.15</td>\n",
       "      <td>21.0</td>\n",
       "      <td>102</td>\n",
       "      <td>1.50</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.218860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>3</td>\n",
       "      <td>12.45</td>\n",
       "      <td>3.03</td>\n",
       "      <td>2.64</td>\n",
       "      <td>27.0</td>\n",
       "      <td>97</td>\n",
       "      <td>1.90</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.393354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>3</td>\n",
       "      <td>14.34</td>\n",
       "      <td>1.68</td>\n",
       "      <td>2.70</td>\n",
       "      <td>25.0</td>\n",
       "      <td>98</td>\n",
       "      <td>2.80</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.241769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>3</td>\n",
       "      <td>13.48</td>\n",
       "      <td>1.67</td>\n",
       "      <td>2.64</td>\n",
       "      <td>22.5</td>\n",
       "      <td>89</td>\n",
       "      <td>2.60</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.143287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>3</td>\n",
       "      <td>12.85</td>\n",
       "      <td>3.27</td>\n",
       "      <td>2.58</td>\n",
       "      <td>22.0</td>\n",
       "      <td>106</td>\n",
       "      <td>1.65</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.239253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>3</td>\n",
       "      <td>12.96</td>\n",
       "      <td>3.45</td>\n",
       "      <td>2.35</td>\n",
       "      <td>18.5</td>\n",
       "      <td>106</td>\n",
       "      <td>1.39</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.126199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>3</td>\n",
       "      <td>13.73</td>\n",
       "      <td>4.36</td>\n",
       "      <td>2.26</td>\n",
       "      <td>22.5</td>\n",
       "      <td>88</td>\n",
       "      <td>1.28</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.305529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>3</td>\n",
       "      <td>14.16</td>\n",
       "      <td>2.51</td>\n",
       "      <td>2.48</td>\n",
       "      <td>20.0</td>\n",
       "      <td>91</td>\n",
       "      <td>1.68</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.107294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>3</td>\n",
       "      <td>13.71</td>\n",
       "      <td>5.65</td>\n",
       "      <td>2.45</td>\n",
       "      <td>20.5</td>\n",
       "      <td>95</td>\n",
       "      <td>1.68</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.319276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>3</td>\n",
       "      <td>13.17</td>\n",
       "      <td>2.59</td>\n",
       "      <td>2.37</td>\n",
       "      <td>20.0</td>\n",
       "      <td>120</td>\n",
       "      <td>1.65</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.141627</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Alcohol  Malic acid   Ash  Alcalinity of ash  Magnesium  Total phenols  \\\n",
       "0          1       14.23  1.71               2.43       15.6            127   \n",
       "8          1       14.83  1.64               2.17       14.0             97   \n",
       "24         1       13.50  1.81               2.61       20.0             96   \n",
       "25         1       13.05  2.05               3.22       25.0            124   \n",
       "29         1       14.02  1.68               2.21       16.0             96   \n",
       "34         1       13.51  1.80               2.65       19.0            110   \n",
       "36         1       13.28  1.64               2.84       15.5            110   \n",
       "42         1       13.88  1.89               2.59       15.0            101   \n",
       "45         1       14.21  4.04               2.44       18.9            111   \n",
       "47         1       13.90  1.68               2.12       16.0            101   \n",
       "51         1       13.83  1.65               2.60       17.2             94   \n",
       "53         1       13.77  1.90               2.68       17.1            115   \n",
       "56         1       14.22  1.70               2.30       16.3            118   \n",
       "64         2       12.17  1.45               2.53       19.0            104   \n",
       "68         2       13.34  0.94               2.36       17.0            110   \n",
       "69         2       12.21  1.19               1.75       16.8            151   \n",
       "70         2       12.29  1.61               2.21       20.4            103   \n",
       "71         2       13.86  1.51               2.67       25.0             86   \n",
       "73         2       12.99  1.67               2.60       30.0            139   \n",
       "76         2       13.03  0.90               1.71       16.0             86   \n",
       "79         2       12.70  3.87               2.40       23.0            101   \n",
       "82         2       12.08  1.13               2.51       24.0             78   \n",
       "85         2       12.67  0.98               2.24       18.0             99   \n",
       "86         2       12.16  1.61               2.31       22.8             90   \n",
       "89         2       12.08  1.33               2.30       23.6             70   \n",
       "90         2       12.08  1.83               2.32       18.5             81   \n",
       "92         2       12.69  1.53               2.26       20.7             80   \n",
       "96         2       11.81  2.12               2.74       21.5            134   \n",
       "102        2       12.34  2.45               2.46       21.0             98   \n",
       "104        2       12.51  1.73               1.98       20.5             85   \n",
       "107        2       12.72  1.75               2.28       22.5             84   \n",
       "108        2       12.22  1.29               1.94       19.0             92   \n",
       "114        2       12.08  1.39               2.50       22.5             84   \n",
       "116        2       11.82  1.47               1.99       20.8             86   \n",
       "117        2       12.42  1.61               2.19       22.5            108   \n",
       "118        2       12.77  3.43               1.98       16.0             80   \n",
       "120        2       11.45  2.40               2.42       20.0             96   \n",
       "124        2       11.87  4.31               2.39       21.0             82   \n",
       "128        2       12.37  1.63               2.30       24.5             88   \n",
       "129        2       12.04  4.30               2.38       22.0             80   \n",
       "130        3       12.86  1.35               2.32       18.0            122   \n",
       "131        3       12.88  2.99               2.40       20.0            104   \n",
       "136        3       12.25  4.72               2.54       21.0             89   \n",
       "141        3       13.36  2.56               2.35       20.0             89   \n",
       "145        3       13.16  3.57               2.15       21.0            102   \n",
       "157        3       12.45  3.03               2.64       27.0             97   \n",
       "158        3       14.34  1.68               2.70       25.0             98   \n",
       "159        3       13.48  1.67               2.64       22.5             89   \n",
       "162        3       12.85  3.27               2.58       22.0            106   \n",
       "163        3       12.96  3.45               2.35       18.5            106   \n",
       "165        3       13.73  4.36               2.26       22.5             88   \n",
       "172        3       14.16  2.51               2.48       20.0             91   \n",
       "173        3       13.71  5.65               2.45       20.5             95   \n",
       "176        3       13.17  2.59               2.37       20.0            120   \n",
       "\n",
       "     Flavanoid  Alcohol_2  Alcohol_3  Intercept  Admit Pred  \n",
       "0         2.80          0          0        1.0    2.831296  \n",
       "8         2.80          0          0        1.0    2.740607  \n",
       "24        2.53          0          0        1.0    2.961953  \n",
       "25        2.63          0          0        1.0    3.180942  \n",
       "29        2.65          0          0        1.0    2.812952  \n",
       "34        2.35          0          0        1.0    2.939728  \n",
       "36        2.60          0          0        1.0    2.805247  \n",
       "42        3.25          0          0        1.0    2.794452  \n",
       "45        2.85          0          0        1.0    3.073542  \n",
       "47        3.10          0          0        1.0    2.818413  \n",
       "51        2.45          0          0        1.0    2.850705  \n",
       "53        3.00          0          0        1.0    2.883483  \n",
       "56        3.20          0          0        1.0    2.847007  \n",
       "64        1.89          1          0        1.0    2.920584  \n",
       "68        2.53          1          0        1.0    2.825363  \n",
       "69        1.85          1          0        1.0    2.875957  \n",
       "70        1.10          1          0        1.0    2.979501  \n",
       "71        2.95          1          0        1.0    3.119474  \n",
       "73        3.30          1          0        1.0    3.360643  \n",
       "76        1.95          1          0        1.0    2.764603  \n",
       "79        2.83          1          0        1.0    3.207002  \n",
       "82        2.00          1          0        1.0    3.052852  \n",
       "85        2.20          1          0        1.0    2.852410  \n",
       "86        1.78          1          0        1.0    3.051758  \n",
       "89        2.20          1          0        1.0    3.043297  \n",
       "90        1.60          1          0        1.0    2.903044  \n",
       "92        1.38          1          0        1.0    2.962139  \n",
       "96        1.60          1          0        1.0    3.079594  \n",
       "102       2.56          1          0        1.0    3.046644  \n",
       "104       2.20          1          0        1.0    2.973239  \n",
       "107       1.38          1          0        1.0    3.043426  \n",
       "108       2.36          1          0        1.0    2.900502  \n",
       "114       2.56          1          0        1.0    3.021583  \n",
       "116       1.98          1          0        1.0    2.969050  \n",
       "117       2.00          1          0        1.0    3.059631  \n",
       "118       1.63          1          0        1.0    2.910905  \n",
       "120       2.90          1          0        1.0    3.006300  \n",
       "124       2.86          1          0        1.0    3.143434  \n",
       "128       2.22          1          0        1.0    3.111602  \n",
       "129       2.10          1          0        1.0    3.176060  \n",
       "130       1.51          0          1        1.0    3.997539  \n",
       "131       1.30          0          1        1.0    4.149493  \n",
       "136       1.38          0          1        1.0    4.274343  \n",
       "141       1.40          0          1        1.0    4.108514  \n",
       "145       1.50          0          1        1.0    4.218860  \n",
       "157       1.90          0          1        1.0    4.393354  \n",
       "158       2.80          0          1        1.0    4.241769  \n",
       "159       2.60          0          1        1.0    4.143287  \n",
       "162       1.65          0          1        1.0    4.239253  \n",
       "163       1.39          0          1        1.0    4.126199  \n",
       "165       1.28          0          1        1.0    4.305529  \n",
       "172       1.68          0          1        1.0    4.107294  \n",
       "173       1.68          0          1        1.0    4.319276  \n",
       "176       1.65          0          1        1.0    4.141627  "
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Analysing the dataset\n",
    "\n",
    "data[data['Admit Pred'].notnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Plot(variable):\n",
    "    # Selecting the variables\n",
    "    results = data[data['Admit Pred'].notnull()]\n",
    "    \n",
    "    grouped = pd.pivot_table(results, values=['Admit Pred'], index=[variable, 'Alcohol'],\n",
    "              aggfunc=np.mean)\n",
    "    # Plotting\n",
    "    for col in data.Alcohol.unique():\n",
    "        plt_data = grouped.iloc[grouped.index.get_level_values(1)==col].reset_index()\n",
    "        pl.plot(plt_data.index.get_level_values(0), plt_data['Alcohol'])\n",
    "\n",
    "    pl.xlabel(variable)\n",
    "    pl.ylabel(\"P(Alcohol)\")\n",
    "    pl.legend(['1', '2', '3'], loc='upper left', title='Alcohol')\n",
    "    pl.title(\"Prob(Alcohol Group) isolating \" + variable + \" and Alcohol\")\n",
    "    pl.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYwAAAEWCAYAAAB1xKBvAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzt3XucFNWd9/HPVyCiAioXjQoIm2i8cRHnQX2Ct2x00dV4\njQsxiLeQZE2e+OSyGjcrmosm2cTH15qoYYOXGEUTr5iXGjFqCGY1DkjAa8IaXAZRRohBE1HA3/NH\nnYG27Z6phqnpuXzfr1e/prvOqapfdXX3r86pmjqKCMzMzNqyVb0DMDOzrsEJw8zMcnHCMDOzXJww\nzMwsFycMMzPLxQnDzMxyccLoZCRdLOmnbdS5TNJ5NSwzJH1wC+NaKumjmznvFq+/o0jaWtJzkoa0\nUudCST/ewvW0uZ/bmP9pSYdvSQztTdIjks6p07q35PN5hqR5W7j+wyU11Wv9HcUJox2kD+ubkt6Q\n9Iqk6yX1K2hdQ4DTgR+VTR8p6R1JVxex3iJJOlLSw5Jel7RK0kJJ50vq29GxRMRbwLXABa3UuTQi\nOuyHMX2evlkWw74R8UiB6zw8Jfrzi1pHR0tJOiQdWO9YuionjPZzXET0A8YBDcDXyisos6Xv+RnA\nvRHxZtn004E/A/8kaestXEeHkfRx4DbgZmD3iBgE/BMwFBhWZZ7eBYd1MzC1K72PBZgKrCb7XHV5\nkkS2Ld1mm+rBCaOdRcRy4D5gP9jYTP+WpEeBvwF/J2lXSbMlrZa0RNKnyhbTV9Kt6Yh7gaQxJWVH\nA78urVzyZfgasA44rlp8kraR9H1JL0r6i6R5krZJZR9LXR2vpbj3Lpt9rKRFab5bS1sAkj6VtmV1\n2rZd23qvUtyXA1+PiP+MiNXpPXw+Ij4fEX9M9S6WdJukn0paA5yRuo6ukPRSelzR8gNfqYlf2i2W\njtivkTQnvce/lrR7S92IaCJLvgdViXtjd5KkvimuVel9e0LSzqmsrf1cusyfS3o5vbdzJe2bpk8D\nTgP+JbVg70nTN3bBpHh+JuknaXueltRQsuxxkp5MZT9P++6bleJI9bcDTgHOBfYoW1bV7U12l/Ro\nWtcDkgZXWceOkn4hqVnSn9PzoSXlj0j6RrVlSZqSPsOrJP1rtW0pcQiwC/B/gEmS3tfK9u+bPhur\nlfUYXJimV/3Mlcz7JUkrJa2QdGbJ9O3T/mlOcX9NW37w2OG6XMCdnaRhwDHAkyWTpwDTgP7Ai8At\nQBOwK9kX81JJHympfzzwc2Ag2dHuXZL6pLJRwPNlq51AdkR+C/AzsqPDar4HHAD877T8fwHekbQn\nMAs4DxgC3AvcU/bFOhWYCIwERpO1dkixX5bKdynZxrZ8KMV9e466x5O1RHYAbgL+lewHfSwwBhhP\nhVZdK04DvgEMBhamZZZ6Ni23LVOB7claQ4OAzwAtrb+29nOp+4A9gJ2ABS3xRMSM9Py7EdEvIqod\nDHwsrW8HYDbwA4C0/+4Erifb37OAE9vYppOAN8g+g7/k3Z+n1rYX4BPAmWk73gd8uco6tgKuA3YH\nhqdl/KCsTsVlSdoHuJrse7VrimMorZsK3EP2/YAqB1WS+gMPAvenZX8Q+FUqbusz936y92Y34Gzg\nh5J2TGVXprK/Aw4jO8A7k64mIvzYwgewlOwL9hrZj+VVwDap7BGyI+iWusOADUD/kmmXAden5xcD\nj5WUbQWsAA5Jr9cBe5Wt/8fAXen5wanOTiXlQfbB34rsizmmwjb8G/CzsvUuBw4v2cZPlpR/F7gm\nPZ9J9oPWUtYvxTCidP0V1jkhlfUtmXZLeh//BkwpeU/mls3738AxJa//AVianp8BzCurvzEGsh/P\nW8ri3QAMK5l2E3BRlf19MfDT9Pws4LfA6LI6efbzT6ssf4cU7/Yl8X6zwmfuoyXLerCkbB/gzfT8\n0LQfVVI+r3x5Zct+ELgiPZ8MNAN9Wtveks/610pe/zNwf87v0Fjgz3mWBVxUtv+2A95ueT8qLHtb\nYA1wQnr9I+DukvKNn5e0vU9WWU5rn7nDyb5bvUvKV5IlmF4pvn1Kyj4NPFLt89pZH25htJ8TImKH\niNg9Iv453n2OYVnJ812B1RHxesm0F8mOSt5TPyLeYdNRKmRdJf1bypV1J32cTUek/wX8D9nRWbnB\nQF+yD365XVMcpetdVhbXyyXP/0b2Q1tp3jeAVWXzVrIq/d2lZN5JEbED2VF2r5K6pe/he9aZnrfZ\nDVZpeSne1WXz9ydLXG25kewo/JbUTfHd1BrMs58BkNRL0rcl/Xfqcluaiip251RRvm/6KjvXsyuw\nPNIvU1L+XpbGMgw4gk0trrvJPjP/mF5X295qcVS8+EPStpJ+lLpn1gBzgR0kle7z1j5vpfvvr2z6\nLFVyIrCerNVM2rajVflKuGFU/n60rLe1z9yqiFhfIebBQJ8K87b1/eh0nDA6RumX9SVgYGr6thhO\ndhTYYuPJ3tTPOTTNB7AI2LOk7onAAOCq1Af+MtkHsVK31KvAWuADFcpeIuseaFmvUhzLK9Rta97t\nyLoJ2pr3+VTnpBzrKL+t8rvWSfYetrxHfyU7qmyJ5/0Vllf6Hvcj6655qaR8b+D3bQYVsS4iLomI\nfci6+Y4l627Is59bfIKsy+2jZN0WI1pCa1lNW3G0YgWwW9qfLSpeTJBMIftduCd9ll4gSxhTodXt\nrdWXyLokD4yIAWQtIdi0za1Zwbv337Zkn7dqppL9cP9P2qafk/2AVzqoWkbWbVRJa5+51rxK1uIu\nnzfPd6tTccLoYBGxjKxJf1k6gTiarL+z9Jr8AySdlI4QzwPeAh5LZfeS9YG2mEp2Gegosmb9WODD\nwBhJo8rW/U6qe7myE7K9JB2cTtz9DPhHSX+fjhi/lNb72xybNQs4U9LYtKxLgccjYmkb78U7aT3T\nlZ0031GZPYCdW5s3rfNrkoakk6EXsek9/D2wb4qnL1mXTbljJE1IffzfIOsGXAYgaTeyBPJYhfne\nRdIRkkalI+M1ZD8M7+Tczy36k73Xq8gS3aVl5a9Q/UesLf9F1jX2OUm9JR1P1vdezVTgEjZ9lsYC\nJ5O9X4Oqbe9mxNWfrAvnNUkDgek1zHsbcGzJ/vs6VX7L0r78e7LE1rI9Y4DvUDnR/QLYRdJ56SR3\nf226DLe1z1xVEbGB7Pv1rbS83YEv5pm3s3HCqI/JZEeRL5GdkJweEQ+WlN9Ndmnpn8mO+E6KiHWp\n7CdkX95tSr4MV0TEyyWP+WQn7Sq1Mr4MLAaeIOuG+Q6wVUQ8D3yS7OTcq2QnBY+LiLfb2pgU+7+R\nnbxeQdaCmZTnjYiIW8lOln+S7OjuVbIv1wyyI8Fqvgk0krW4FpN1YX0zLfMPZD8iDwJ/JOuzL3cz\n2Y/UarKLAD5ZUvYJ4IbI/iejLe8n+wFbQ3ai/Ndk3TbQ9n5u8ROyLorlwDO8N1HNBPZRdlXSXTli\n2ijtv5PIktVrZNv5C7IE9S6SDiI7Cv5h2edpNrAkbU9r21uLK4BtyPb3Y2Sf17zb9DTZFVw3k33e\n/kzWbVvJFGBhRDxQuk3AfwCjJe1XtuzXgSPJPv8vk31+jkjFVT9zOXyerOX7Atnn8Wayg7cuRe/u\n2rSuQNKlwMqIuKLesXRFkq4HmiKi0v/KbE3WQjk0IlZ2dGwdQdLjZBcsXFfvWKxrKfofoKwAEXFh\nvWPorlKrYq96x9GeJB1Gdr7oVbLLiUdTwxG9WQsnDLPu70Nk3XzbkXWJnBIRK+obknVF7pIyM7Nc\nfNLbzMxy6VZdUoMHD44RI0bUOwwzsy5j/vz5r0ZE1dv5l+pWCWPEiBE0NjbWOwwzsy5D0ott18q4\nS8rMzHJxwjAzs1ycMMzMLJdudQ6jknXr1tHU1MTatWvrHUqb+vbty9ChQ+nTp0/blc3MOli3TxhN\nTU3079+fESNG8O4bdnYuEcGqVatoampi5MiR9Q7HzOw9CuuSSnfo/J2k3ysbMvKSCnW2VjZc5BJJ\nj0saUVL21TT9eUn/sLlxrF27lkGDBnXqZAEgiUGDBnWJlpCZ9UxFnsN4C/hIRIwhu6XwxHQ3zFJn\nk42y9UHg/5HdObVlCMZJwL5kQ4JeVTawSk06e7Jo0VXiNLOeqbAuqTTC1xvpZZ/0KL8PyfFsGqvg\nNuAHaaCX48mGYHwL+JOkJWT38P+vImJd8dcVrF3fOY7sX33zVc68v+sN9Wvtb6+Be3H++PPrHYbZ\nRoVeJZUG6FlINrbtnIh4vKzKbqShFtPQhn8hGzlr4/SkiSrDGUqaJqlRUmNzc3Pu2O666y4k8dxz\nz2UreLGJiQdPzD1/qUNGHcLqVatz17/tptuY/pVaxosxM6u/Qk96p5GmxkraAbhT0n4R8VQ7r2MG\n2WA7NDQ05L6T4qxZs5gwYQKzZs3ikksu4a0Bb9Fnqz6M3L72E869t+rN7gN2Z/D2+YZgHrLtEAa8\nb0DFda3dZi3XTfQwBWbW+XTI/2FExGvAw2TnI0otJ43Nm4Yj3Z5smMqN05OhtOP4t2+88Qbz5s1j\n5syZ3HLLLe8p37BhA1/+8pfZb7/9GD16NFdeeSUAv/rVr9h///0ZNWoUZ511Fm+9tWnQsiuvvJJx\n48YxatSoja2W1atXc8IJJzB69GgOOuggFi1a1F6bYGbW4Yq8SmpIalkgaRuyYQ+fK6s2m03DiJ4C\nPJTOfcwGJqWrqEYCewC/a6/Y7r77biZOnMiee+7JoEGDmD9//rvKZ8yYwdKlS1m4cCGLFi3itNNO\nY+3atZxxxhnceuutLF68mPXr13P11VdvnGfw4MEsWLCAz372s3zve98DYPr06ey///4sWrSISy+9\nlNNPrzSEsJlZ11BkC2MX4GFJi8jGj54TEb+Q9HVJH0t1ZgKD0kntLwIXwMYxe39GNr7x/cC5qXur\nXcyaNYtJk7IhpydNmsSsWbPeVf7ggw/y6U9/mt69sx67gQMH8vzzzzNy5Ej23HNPAKZOncrcuXM3\nznPSSScBcMABB7B06VIA5s2bx5QpUwD4yEc+wqpVq1izZk17bYaZWYcq8iqpRcD+FaZfVPJ8LfDx\nKvN/C/hWe8e1evVqHnroIRYvXowkNmzYgCTOPffcLVru1ltvDUCvXr1Yv359e4RqZtap9Lh7Sd12\n221MmTKFF198kaVLl7Js2TJGjhzJsmWbLso68sgj+dGPfrTxh3/16tV86EMfYunSpSxZsgSAG2+8\nkcMOO6zVdR1yyCHcdNNNADzyyCMMHjyYAQMGFLRlZmbF6nEJY9asWZx44onvmnbyySdz2WWXbXx9\nzjnnMHz4cEaPHs2YMWO4+eab6du3L9dddx0f//jHGTVqFFtttRWf+cxnWl3XxRdfzPz58xk9ejQX\nXHABN9xwQyHbZGbWEbrVmN4NDQ1RPoDSs88+y957712niGrX1eI1s65N0vyIaMhTt8e1MMzMbPM4\nYZiZWS5OGGZmlosThpmZ5eKEYWZmuThhmJlZLk4YHeSss85ip512Yr/99qt3KGZmm8UJo4OcccYZ\n3H///fUOw8xsszlhdJBDDz2UgQMH1jsMM7PNVugASp3RJfc8zTMvte8dY/fZdQDTj9u3XZdpZtbZ\nuIVhZma59LgWhlsCZmabxy0MMzPLpcghWodJeljSM5KelvSFCnW+ImlhejwlaYOkgalsqaTFqazx\nvWvoWiZPnszBBx/M888/z9ChQ5k5c2a9QzIzq0mRXVLrgS9FxAJJ/YH5kuZExDMtFSLi34F/B5B0\nHPB/I2J1yTKOiIhXC4yxw5QPA2tm1tUU1sKIiBURsSA9fx14FtitlVkmA/5VNTPrpDrkHIakEWTj\nez9epXxbYCJwe8nkAB6QNF/StFaWPU1So6TG5ubm9gvazMzepfCEIakfWSI4LyKq/QPEccCjZd1R\nEyJiHHA0cK6kQyvNGBEzIqIhIhqGDBnSrrGbmdkmhSYMSX3IksVNEXFHK1UnUdYdFRHL09+VwJ3A\n+KLiNDOzthV5lZSAmcCzEXF5K/W2Bw4D7i6Ztl06UY6k7YCjgKeKitXMzNpW5FVSHwamAIslLUzT\nLgSGA0TENWnaicADEfHXknl3Bu7Mcg69gZsjwnfuMzOro8ISRkTMA5Sj3vXA9WXTXgDGFBJYHSxb\ntozTTz+dV155BUlMmzaNL3zhPf+WYmbWqfW4W4PUQ+/evfn+97/PuHHjeP311znggAM48sgj2Wef\nfeodmplZbr41SAfYZZddGDduHAD9+/dn7733Zvny5XWOysysNj2vhXHfBfDy4vZd5vtHwdHfzlV1\n6dKlPPnkkxx44IHtG4OZWcHcwuhAb7zxBieffDJXXHEFAwYMqHc4ZmY16XktjJwtgfa2bt06Tj75\nZE477TROOumkusRgZrYl3MLoABHB2Wefzd57780Xv/jFeodjZrZZnDA6wKOPPsqNN97IQw89xNix\nYxk7diz33ntvvcMyM6tJz+uSqoMJEyYQEfUOw8xsi7iFYWZmuThhmJlZLk4YZmaWixOGmZnl4oRh\nZma5OGGYmVkuThgdYO3atYwfP54xY8aw7777Mn369HqHZGZWM/8fRgfYeuuteeihh+jXrx/r1q1j\nwoQJHH300Rx00EH1Ds3MLLcih2gdJulhSc9IelrSe0YMknS4pL9IWpgeF5WUTZT0vKQlki4oKs6O\nIIl+/foB2T2l1q1bRxpN0MysyyiyhbEe+FJELEjjc8+XNCcinimr95uIOLZ0gqRewA+BI4Em4AlJ\nsyvMW7Pv/O47PLf6uS1dzLvsNXAvzh9/fqt1NmzYwAEHHMCSJUs499xzfXtzM+tyCmthRMSKiFiQ\nnr8OPAvslnP28cCSiHghIt4GbgGOLybSjtGrVy8WLlxIU1MTv/vd73jqqafqHZKZWU065ByGpBHA\n/sDjFYoPlvR74CXgyxHxNFliWVZSpwmoeEguaRowDWD48OFtxtJWS6BoO+ywA0cccQT3338/++23\nX11jMTOrReFXSUnqB9wOnBcRa8qKFwC7R8QY4ErgrlqXHxEzIqIhIhqGDBmy5QEXoLm5mddeew2A\nN998kzlz5rDXXnvVOSozs9oU2sKQ1IcsWdwUEXeUl5cmkIi4V9JVkgYDy4FhJVWHpmld0ooVK5g6\ndSobNmzgnXfe4dRTT+XYY49te0Yzs06ksISh7DKgmcCzEXF5lTrvB16JiJA0nqzFswp4DdhD0kiy\nRDEJ+ERRsRZt9OjRPPnkk/UOw8xsixTZwvgwMAVYLGlhmnYhMBwgIq4BTgE+K2k98CYwKbKBI9ZL\n+hzwS6AXcG06t2FmZnVSWMKIiHlAq/9sEBE/AH5QpexewMPSmZl1Ej3i1iBdZbS7rhKnmfVM3T5h\n9O3bl1WrVnX6H+OIYNWqVfTt27feoZiZVdTt7yU1dOhQmpqaaG5urncoberbty9Dhw6tdxhmZhV1\n+4TRp08fRo4cWe8wzMy6vG7fJWVmZu3DCcPMzHJxwjAzs1ycMMzMLBcnDDMzy8UJw8zMcnHCMDOz\nXJwwzMwsFycMMzPLxQnDzMxyccIwM7NcCksYkoZJeljSM5KelvSFCnVOk7RI0mJJv5U0pqRsaZq+\nUFJjUXGamVk+Rd58cD3wpYhYIKk/MF/SnIh4pqTOn4DDIuLPko4GZgAHlpQfERGvFhijmZnlVOSI\neyuAFen565KeBXYDnimp89uSWR4DfG9vM7NOqkPOYUgaAewPPN5KtbOB+0peB/CApPmSprWy7GmS\nGiU1doUxL8zMuqrCx8OQ1A+4HTgvItZUqXMEWcKYUDJ5QkQsl7QTMEfScxExt3zeiJhB1pVFQ0ND\n5x5Wz8ysCyu0hSGpD1myuCki7qhSZzTwY+D4iFjVMj0ilqe/K4E7gfFFxmpmZq3L3cJIR/ofBnYF\n3gSeAhoj4p0q9QXMBJ6NiMur1BkO3AFMiYg/lEzfDtgqnfvYDjgK+HreWM3MrP21mTBSd9EFwEDg\nSWAl0Bc4AfiApNuA71fobvowMAVYLGlhmnYhMBwgIq4BLgIGAVdl+YX1EdEA7Azcmab1Bm6OiPu3\nYDvNzGwL5WlhHAN8KiL+p7xAUm/gWOBIsq6njSJiHqDWFhwR5wDnVJj+AjDmvXOYmVm9tJkwIuIr\nrZStB+5q14jMzKxTytMl9cXWyqudnzAzs+4lT5dU/8KjMDOzTi9Pl9QlHRGImZl1brn/D0PSUEl3\nSlqZHrdL8q08zMx6iFr+ce86YDbZ/2HsCtyTppmZWQ9QS8IYEhHXRcT69LgeGFJQXGZm1snUkjBW\nSfqkpF7p8UlgVZtzmZlZt1BLwjgLOBV4mey25acAZxYRlJmZdT657yUVES8CHyswFjMz68Rqufng\nEOBTwIjS+SLirPYPy8zMOptaxsO4G/gN8CCwoZhwzMyss6olYWwbEecXFomZmXVqtZz0/oWkYwqL\nxMzMOrU8Nx98nWx8bQEXSnobWJeKIyIGFBifmZl1EnnuJeWbD5qZWW1jekv6mKTvpcexbdQdJulh\nSc9IelrSFyrUkaT/kLRE0iJJ40rKpkr6Y3pMrSVOMzNrf7VcVvtt4H8BN6VJX5D04Yj4apVZ1gNf\niogFkvoD8yXNiYhnSuocDeyRHgcCVwMHShoITAcayLrD5kuaHRF/rmXjzMys/dRyldQxwNiIeAdA\n0g1kY3xXTBgRsYLsP8KJiNclPQvsBpQmjOOBn0REAI9J2kHSLsDhwJyIWJ3WNQeYCMyqId787rsA\nXl5cyKLNzAr3/lFw9LcLX01NXVLADiXPt887k6QRwP7A42VFuwHLSl43pWnVplda9jRJjZIam5ub\n84ZkZmY1qqWFcRnwpKSHya6YOhS4oK2ZJPUDbgfOi4g1mxVlKyJiBjADoKGhITZrIR2Qmc3Murpa\n7iU1S9IjZOcxAM6PiJdbm0dSH7JkcVNE3FGhynJgWMnroWnacrJuqdLpj+SN1czM2l8tI+6dCPwt\nImZHxGxgraQTWqkvYCbwbERcXqXabOD0dLXUQcBf0rmPXwJHSdpR0o7AUWmamZnVSS1dUtMj4s6W\nFxHxmqTpwF1V6n8YmAIslrQwTbsQGJ7mvwa4l+xk+hLgb6TbpUfEaknfAJ5I83295QS4mZnVRy0J\no1JrpOr8ETGP7FxHVenqqHOrlF0LXFtDfGZmVqBarpJqlHS5pA+kx+XA/KICMzOzzqWWhPF54G3g\n1vR4iyqtAzMz635quUrqr+S4jNbMzLqnPHervYfs9hwVRYSHbTUz6wHytDC+V3gUZmbW6eW5vfmv\nK02XNAyYBFQsNzOz7qXW25sPkfTPkn5D9p/XOxcSlZmZdTp5zmH0B04CPgHsCdwBjIyIoQXHZmZm\nnUiecxgrgd8BXwPmRUSk24SYmVkPkqdL6qvA1sBVwFclfaDYkMzMrDNqM2FExBURcRDZYEeQ3Ttq\nV0nnS9qz0OjMzKzTyH3SOyJeiIhLI2IU2dCpA8huHmhmZj1Amwkj3ab8XSLiqYj414j4YLU6ZmbW\nveRpYTws6fOShpdOlPQ+SR9JY3tPLSY8MzPrLPJcJTUROAuYJWkk8BrQF+gFPABcERFPFheimZl1\nBnn+03st2RVSV6UhVwcDb0bEa0UHZ2ZmnUeef9zrC3wG+CCwCLg2ItbnmO9a4FhgZUTsV6H8K8Bp\nJXHsDQxJo+0tBV4HNgDrI6Ih3+aYmVlR8pzDuIHsqqjFZMOpfj/nsq8n686qKCL+PSLGRsRYsv/1\n+HXZMKxHpHInCzOzTiDPOYx90qW0SJpJ9l/fbYqIuZJG5IxjMjArZ10zM6uDPC2MdS1P8nRF1UrS\ntmQtkdtLJgfwgKT5kqa1Mf80SY2SGpubm9s7PDMzS/K0MMZIWpOeC9gmvRYQETFgC2M4Dni0rDtq\nQkQsl7QTMEfScxExt9LMETEDmAHQ0NBQdaAnMzPbMnmukupVcAyTKOuOiojl6e9KSXcC44GKCcPM\nzDpGTeNhtDdJ2wOHAXeXTNsu3VIdSdsBRwFP1SdCMzNrkadLarNImgUcDgyW1ARMB/oARMQ1qdqJ\nwAMR8deSWXcG7kx3G+kN3BwR9xcVp5mZ5VNYwoiIyTnqXE92+W3ptBeAMcVEZWZmm6uuXVJmZtZ1\nOGGYmVkuThhmZpaLE4aZmeXihGFmZrk4YZiZWS5OGGZmlosThpmZ5eKEYWZmuThhmJlZLk4YZmaW\nixOGmZnl4oRhZma5OGGYmVkuThhmZpZLYQlD0rWSVkqqOFqepMMl/UXSwvS4qKRsoqTnJS2RdEFR\nMZqZWX5FtjCuBya2Uec3ETE2Pb4OIKkX8EPgaGAfYLKkfQqM08zMcigsYUTEXGD1Zsw6HlgSES9E\nxNvALcDx7RqcmZnVrN7nMA6W9HtJ90naN03bDVhWUqcpTatI0jRJjZIam5ubi4zVzKxHq2fCWADs\nHhFjgCuBuzZnIRExIyIaIqJhyJAh7RqgmZltUreEERFrIuKN9PxeoI+kwcByYFhJ1aFpmpmZ1VHd\nEoak90tSej4+xbIKeALYQ9JISe8DJgGz6xWnmZllehe1YEmzgMOBwZKagOlAH4CIuAY4BfispPXA\nm8CkiAhgvaTPAb8EegHXRsTTRcVpZmb5KPuN7h4aGhqisbGx3mGYmXUZkuZHREOeuvW+SsrMzLoI\nJwwzM8vFCcPMzHJxwjAzs1ycMMzMLBcnDDMzy8UJw8zMcnHCMDOzXJwwzMwsFycMMzPLxQnDzMxy\nccIwM7NcnDDMzCwXJwwzM8vFCcPMzHJxwjAzs1wKSxiSrpW0UtJTVcpPk7RI0mJJv5U0pqRsaZq+\nUJJHRDIz6wSKbGFcD0xspfxPwGERMQr4BjCjrPyIiBibdyQoMzMrVmFjekfEXEkjWin/bcnLx4Ch\nRcViZmZbrrOcwzgbuK/kdQAPSJovaVprM0qaJqlRUmNzc3OhQZqZ9WSFtTDyknQEWcKYUDJ5QkQs\nl7QTMEfScxExt9L8ETGD1J3V0NAQhQdsZtZD1bWFIWk08GPg+IhY1TI9IpanvyuBO4Hx9YnQzMxa\n1C1hSBoO3AFMiYg/lEzfTlL/lufAUUDFK63MzKzjFNYlJWkWcDgwWFITMB3oAxAR1wAXAYOAqyQB\nrE9XRO0LeFOGAAAGEklEQVQM3Jmm9QZujoj7i4rTzMzyKfIqqcltlJ8DnFNh+gvAmPfOYWZm9dRZ\nrpIyM7NOzgnDzMxyccIwM7NcnDDMzCwXJwwzM8vFCcPMzHJxwjAzs1ycMMzMLBcnDDMzy8UJw8zM\ncnHCMDOzXJwwzMwsFycMMzPLxQnDzMxyccIwM7NcnDDMzCyXQhOGpGslrZRUcYhVZf5D0hJJiySN\nKymbKumP6TG1yDjNzKxtRbcwrgcmtlJ+NLBHekwDrgaQNJBsSNcDgfHAdEk7FhqpmZm1qrAhWgEi\nYq6kEa1UOR74SUQE8JikHSTtQjYW+JyIWA0gaQ5Z4plVRJyX3PM0z7y0pohFWxewz64DmH7cvvUO\nw6zTq/c5jN2AZSWvm9K0atPfQ9I0SY2SGpubmwsL1Myspyu0hdERImIGMAOgoaEhNmcZPro0M2tb\nvVsYy4FhJa+HpmnVppuZWZ3UO2HMBk5PV0sdBPwlIlYAvwSOkrRjOtl9VJpmZmZ1UmiXlKRZZCew\nB0tqIrvyqQ9ARFwD3AscAywB/gacmcpWS/oG8ERa1NdbToCbmVl9FH2V1OQ2ygM4t0rZtcC1RcRl\nZma1q3eXlJmZdRFOGGZmlosThpmZ5eKEYWZmuSg779w9SGoGXtzM2QcDr7ZjOF1JT9526Nnb723v\nuVq2f/eIGJJnhm6VMLaEpMaIaKh3HPXQk7cdevb2e9t75rbD5m2/u6TMzCwXJwwzM8vFCWOTGfUO\noI568rZDz95+b3vPVfP2+xyGmZnl4haGmZnl4oRhZma59PiEIWmipOclLZF0Qb3j6WiSlkpaLGmh\npMZ6x1MkSddKWinpqZJpAyXNkfTH9Lfbjh1fZfsvlrQ87f+Fko6pZ4xFkTRM0sOSnpH0tKQvpOnd\nfv+3su017/sefQ5DUi/gD8CRZMPAPgFMjohn6hpYB5K0FGiIiG7/D0ySDgXeIBtHfr807bvA6oj4\ndjpg2DEizq9nnEWpsv0XA29ExPfqGVvRJO0C7BIRCyT1B+YDJwBn0M33fyvbfio17vue3sIYDyyJ\niBci4m3gFuD4OsdkBYmIuUD5uCrHAzek5zeQfZG6pSrb3yNExIqIWJCevw48C+xGD9j/rWx7zXp6\nwtgNWFbyuonNfCO7sAAekDRf0rR6B1MHO6dRHgFeBnauZzB18jlJi1KXVbfrkiknaQSwP/A4PWz/\nl2071Ljve3rCMJgQEeOAo4FzU7dFj5QG9OppfbRXAx8AxgIrgO/XN5xiSeoH3A6cFxFrSsu6+/6v\nsO017/uenjCWA8NKXg9N03qMiFie/q4E7iTrputJXkl9vC19vSvrHE+HiohXImJDRLwD/CfdeP9L\n6kP2g3lTRNyRJveI/V9p2zdn3/f0hPEEsIekkZLeB0wCZtc5pg4jabt0EgxJ2wFHAU+1Ple3MxuY\nmp5PBe6uYywdruXHMjmRbrr/JQmYCTwbEZeXFHX7/V9t2zdn3/foq6QA0qVkVwC9gGsj4lt1DqnD\nSPo7slYFZOO739ydt1/SLOBwsts6vwJMB+4CfgYMJ7s1/qkR0S1PDFfZ/sPJuiQCWAp8uqRPv9uQ\nNAH4DbAYeCdNvpCsL79b7/9Wtn0yNe77Hp8wzMwsn57eJWVmZjk5YZiZWS5OGGZmlosThpmZ5eKE\nYWZmuThhmLUTSSdICkl7tVHvjY6Kyaw9OWGYtZ/JwLz016zbccIwawfpPj0TgLPJ7hiApF0kzU1j\nDTwl6ZCS+t+S9HtJj0nq1je8s+7DCcOsfRwP3B8RfwBWSToA+ATwy4gYC4wBFqa62wGPRcQYYC7w\nqXoEbFYrJwyz9jGZbDwV0t/JZPcqOzMNUjQqjUUA8Dbwi/R8PjCi48I023y96x2AWVcnaSDwEWCU\npCC7L1kAXwEOBf4RuF7S5RHxE2BdbLonzwb8PbQuwi0Msy13CnBjROweESMiYhjwJ7Jk8UpE/Cfw\nY2BcPYM021I+sjHbcpOB75RNux24HvirpHVkY2mf3sFxmbUr363WzMxycZeUmZnl4oRhZma5OGGY\nmVkuThhmZpaLE4aZmeXihGFmZrk4YZiZWS7/H9a45rYJAnWFAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10bbdea20>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Plot('Ash')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluating - Confusion Matrix + ROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ROC = data[data['Admit Pred'].notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Getting the real and predicted values\n",
    "\n",
    "true = np.array(ROC['Alcohol'])\n",
    "\n",
    "# from float to round down int variables\n",
    "predict_ = np.array(ROC['Admit Pred'])\n",
    "predict = np.floor(predict_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The predicted values go over 3 (the maximum class). We need to floor to 3\n",
    "for index in range(len(predict)):\n",
    "    if predict[index] > 3:\n",
    "        predict[index] = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0, 11,  2],\n",
       "       [ 0, 12, 15],\n",
       "       [ 0,  0, 14]])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(true, predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO: PLOT ROC! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification with Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preparation - Local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Once the linear and logistic regression will use the same persistence we only need to remove the predictions\n",
    "# from the last dataset \n",
    "data_ = data.iloc[:,:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Alcohol</th>\n",
       "      <th>Malic acid</th>\n",
       "      <th>Ash</th>\n",
       "      <th>Alcalinity of ash</th>\n",
       "      <th>Magnesium</th>\n",
       "      <th>Total phenols</th>\n",
       "      <th>Flavanoid</th>\n",
       "      <th>Alcohol_2</th>\n",
       "      <th>Alcohol_3</th>\n",
       "      <th>Intercept</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>14.23</td>\n",
       "      <td>1.71</td>\n",
       "      <td>2.43</td>\n",
       "      <td>15.6</td>\n",
       "      <td>127</td>\n",
       "      <td>2.80</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>13.20</td>\n",
       "      <td>1.78</td>\n",
       "      <td>2.14</td>\n",
       "      <td>11.2</td>\n",
       "      <td>100</td>\n",
       "      <td>2.65</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>13.16</td>\n",
       "      <td>2.36</td>\n",
       "      <td>2.67</td>\n",
       "      <td>18.6</td>\n",
       "      <td>101</td>\n",
       "      <td>2.80</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Alcohol  Malic acid   Ash  Alcalinity of ash  Magnesium  Total phenols  \\\n",
       "0        1       14.23  1.71               2.43       15.6            127   \n",
       "1        1       13.20  1.78               2.14       11.2            100   \n",
       "2        1       13.16  2.36               2.67       18.6            101   \n",
       "\n",
       "   Flavanoid  Alcohol_2  Alcohol_3  Intercept  \n",
       "0       2.80          0          0        1.0  \n",
       "1       2.65          0          0        1.0  \n",
       "2       2.80          0          0        1.0  "
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_.head(3)\n",
    "\n",
    "# Lets use the Total Phenols as our predictor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ClassificationLOGIT(dataset):\n",
    "\n",
    "    # Spliting the data into train and test\n",
    "    # 80% -> Training \n",
    "    # 20% -> Testing\n",
    "    \n",
    "    #trainData = dataset.iloc[:int(len(dataset)*.8),:]\n",
    "    #testData = dataset.iloc[int(len(dataset)*.8+1):]\n",
    "    trainData, testData = train_test_split(dataset, test_size = 0.3)\n",
    "    \n",
    "    # Linear regression\n",
    "    # On the train data the dependet variable and the intercept are removed\n",
    "    logit = sm.Logit(trainData['Alcohol'], trainData['Total phenols'])\n",
    "\n",
    "    # Fitting\n",
    "    res = logit.fit()\n",
    "\n",
    "    print(res.summary())\n",
    " \n",
    "    # Generating the odds ratio, based on the exponential of each coefficient \n",
    "    print(\"\\n-----\\nOdds Ratio\\n\")\n",
    "    print(np.exp(res.params))\n",
    "    \n",
    "    # Adding the predicted values on another colunm\n",
    "    dataset['Admit Pred'] = res.predict((testData.iloc[:,2:]))\n",
    "    #print(res.predict(testData.iloc[:,2:]))\n",
    "    return res, dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification using Nave Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preparation - Local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Getting only the dependent and independet variables (predictors)\n",
    "data_b = data.iloc[:,:-4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Alcohol</th>\n",
       "      <th>Malic acid</th>\n",
       "      <th>Ash</th>\n",
       "      <th>Alcalinity of ash</th>\n",
       "      <th>Magnesium</th>\n",
       "      <th>Total phenols</th>\n",
       "      <th>Flavanoid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>14.23</td>\n",
       "      <td>1.71</td>\n",
       "      <td>2.43</td>\n",
       "      <td>15.6</td>\n",
       "      <td>127</td>\n",
       "      <td>2.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>13.20</td>\n",
       "      <td>1.78</td>\n",
       "      <td>2.14</td>\n",
       "      <td>11.2</td>\n",
       "      <td>100</td>\n",
       "      <td>2.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>13.16</td>\n",
       "      <td>2.36</td>\n",
       "      <td>2.67</td>\n",
       "      <td>18.6</td>\n",
       "      <td>101</td>\n",
       "      <td>2.80</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Alcohol  Malic acid   Ash  Alcalinity of ash  Magnesium  Total phenols  \\\n",
       "0        1       14.23  1.71               2.43       15.6            127   \n",
       "1        1       13.20  1.78               2.14       11.2            100   \n",
       "2        1       13.16  2.36               2.67       18.6            101   \n",
       "\n",
       "   Flavanoid  \n",
       "0       2.80  \n",
       "1       2.65  \n",
       "2       2.80  "
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_b.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Splitting the data into Training and Test\n",
    "\n",
    "trainDataBayes, testDataBayes = train_test_split(data_b, test_size = 0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Instantiating the object for NB\n",
    "gnb = GaussianNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Running Bayes\n",
    "res = gnb.fit(trainDataBayes.iloc[:,1:], trainDataBayes.Alcohol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "testDataBayes['Admit Pred'] = res.predict(testDataBayes.iloc[:,1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Alcohol</th>\n",
       "      <th>Malic acid</th>\n",
       "      <th>Ash</th>\n",
       "      <th>Alcalinity of ash</th>\n",
       "      <th>Magnesium</th>\n",
       "      <th>Total phenols</th>\n",
       "      <th>Flavanoid</th>\n",
       "      <th>Admit Pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>3</td>\n",
       "      <td>12.87</td>\n",
       "      <td>4.61</td>\n",
       "      <td>2.48</td>\n",
       "      <td>21.5</td>\n",
       "      <td>86</td>\n",
       "      <td>1.70</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>2</td>\n",
       "      <td>12.37</td>\n",
       "      <td>1.07</td>\n",
       "      <td>2.10</td>\n",
       "      <td>18.5</td>\n",
       "      <td>88</td>\n",
       "      <td>3.52</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1</td>\n",
       "      <td>13.64</td>\n",
       "      <td>3.10</td>\n",
       "      <td>2.56</td>\n",
       "      <td>15.2</td>\n",
       "      <td>116</td>\n",
       "      <td>2.70</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>2</td>\n",
       "      <td>12.29</td>\n",
       "      <td>1.61</td>\n",
       "      <td>2.21</td>\n",
       "      <td>20.4</td>\n",
       "      <td>103</td>\n",
       "      <td>1.10</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Alcohol  Malic acid   Ash  Alcalinity of ash  Magnesium  Total phenols  \\\n",
       "147        3       12.87  4.61               2.48       21.5             86   \n",
       "98         2       12.37  1.07               2.10       18.5             88   \n",
       "19         1       13.64  3.10               2.56       15.2            116   \n",
       "70         2       12.29  1.61               2.21       20.4            103   \n",
       "\n",
       "     Flavanoid  Admit Pred  \n",
       "147       1.70           3  \n",
       "98        3.52           2  \n",
       "19        2.70           1  \n",
       "70        1.10           2  "
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testDataBayes.head(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[16,  1,  0],\n",
       "       [ 1, 20,  4],\n",
       "       [ 0,  0, 12]])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(testDataBayes.Alcohol, testDataBayes['Admit Pred'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.888888888889\n"
     ]
    }
   ],
   "source": [
    "print(sum(testDataBayes['Admit Pred'] == testDataBayes.Alcohol)/ len(testDataBayes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Discriminant Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "\n",
    "# Getting only the dependent and independet variables (predictors)\n",
    "data_lda = data.iloc[:,:-4]\n",
    "\n",
    "# Splitting the data into Training and Test\n",
    "\n",
    "trainDataLDA, testDataLDA = train_test_split(data_lda, test_size = 0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = trainDataLDA.drop('Alcohol', axis=1)\n",
    "y = trainDataLDA.Alcohol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearDiscriminantAnalysis(n_components=3, priors=None, shrinkage=None,\n",
       "              solver='svd', store_covariance=False, tol=0.0001)"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiating the object and fitting\n",
    "res = LDA(n_components=3)\n",
    "res.fit(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "testDataLDA['Admit Pred'] = res.predict(testDataLDA.iloc[:,1:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[17,  0,  0],\n",
       "       [ 1, 22,  2],\n",
       "       [ 2,  1,  9]])"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(testDataLDA.Alcohol, testDataLDA['Admit Pred'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.888888888889\n"
     ]
    }
   ],
   "source": [
    "print(sum(testDataLDA['Admit Pred'] == testDataLDA.Alcohol)/ len(testDataLDA))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
